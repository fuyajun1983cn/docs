To follow the path of network data, we’ll need to move into the
    qdisc code a bit. This post does not intend to cover the specific
    details of each of the different transmit queue options. If you
    are interested in that, [[http://lartc.org/howto/index.html][check this excellent guide]]. 

    For the purpose of this blog post, we’ll continue the code path
    by examining how the generic packet scheduler code works. In
    particular, we’ll explore how =qdisc_run_begin=, =qdisc_run_end=,
    =__qdisc_run=, and =sch_direct_xmit= work to move network data closer
    to the driver for transmit. 

    Let’s start by examining how =qdisc_run_begin= works and proceed from there.

*** =qdisc_run_begin= and =qdisc_run_end=
    The =qdisc_run_begin= function can be found in
    [[https://github.com/torvalds/linux/blob/v3.13/include/net/sch_generic.h#L101-L107][./include/net/sch_generic.h]]: 

    #+BEGIN_SRC c
      static inline bool qdisc_run_begin(struct Qdisc *qdisc)
      {
              if (qdisc_is_running(qdisc))
                      return false;
              qdisc->__state |= __QDISC___STATE_RUNNING;
              return true;
      }    
    #+END_SRC

    This function is simple: the qdisc =__state= flag is checked. If
    it’s already running, =false= is returned. Otherwise, =__state= is
    updated to enable the =__QDISC___STATE_RUNNING= bit. 

    Similarly, =qdisc_run_end= [[https://github.com/torvalds/linux/blob/v3.13/include/net/sch_generic.h#L109-L113][is anti-climactic]]: 

    #+BEGIN_SRC c
      static inline void qdisc_run_end(struct Qdisc *qdisc)
      {
              qdisc->__state &= ~__QDISC___STATE_RUNNING;
      }    
    #+END_SRC

    It simply disables the =__QDISC___STATE_RUNNING= bit from the
    qdisc’s =__state= field. It is important to note that both of these
    functions simply flip bits; neither actually start or stop
    processing themselves. The function =__qdisc_run=, on the other
    hand, will actually start processing. 

*** =__qdisc_run=
    The code for =__qdisc_run= is deceptively brief:
    
    #+BEGIN_SRC c
      void __qdisc_run(struct Qdisc *q)
      {
              int quota = weight_p;

              while (qdisc_restart(q)) {
                      /*
                       ,* Ordered by possible occurrence: Postpone processing if
                       ,* 1. we've exceeded packet quota
                       ,* 2. another process needs the CPU;
                       ,*/
                      if (--quota <= 0 || need_resched()) {
                              __netif_schedule(q);
                              break;
                      }
              }

              qdisc_run_end(q);
      }    
    #+END_SRC

    This function begins by obtaining the =weight_p= value. This is set
    typically via a sysctl and is also used in the receive
    path. We’ll see later how to adjust this value. This loop does
    two things: 
    
    1. It calls =qdisc_restart= in a busy loop until it returns false
       (or the break below is triggered).
    2. Determines if either the quota drops below zero or
       =need_resched()= returns true. If either is true,
       =__netif_schedule= is called and the loop is broken out of. 

    Remember: up to now the kernel is still executing on behalf of the
    original call to =sendmsg= by the user program; the user program is
    currently accumulating system time. If the user program has
    exhausted its time quota in the kernel, =need_resched= will return
    true. If there’s still available quota and the user program
    hasn’t used is time slice up yet, =qdisc_restart= will be called
    over again.    

    Let’s see how =qdisc_restart(q)= works and then we’ll dive into
    =__netif_schedule(q)=. 
    
*** =qdisc_restart=
    Let’s jump into [[https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L156-L192][the code for]] =qdisc_restart=. 
    
    #+BEGIN_SRC c
      /*
       ,* NOTE: Called under qdisc_lock(q) with locally disabled BH.
       ,*
       ,* __QDISC_STATE_RUNNING guarantees only one CPU can process
       ,* this qdisc at a time. qdisc_lock(q) serializes queue accesses for
       ,* this queue.
       ,*
       ,*  netif_tx_lock serializes accesses to device driver.
       ,*
       ,*  qdisc_lock(q) and netif_tx_lock are mutually exclusive,
       ,*  if one is grabbed, another must be free.
       ,*
       ,* Note, that this procedure can be called by a watchdog timer
       ,*
       ,* Returns to the caller:
       ,*                                0  - queue is empty or throttled.
       ,*                                >0 - queue is not empty.
       ,*
       ,*/
      static inline int qdisc_restart(struct Qdisc *q)
      {
              struct netdev_queue *txq;
              struct net_device *dev;
              spinlock_t *root_lock;
              struct sk_buff *skb;

              /* Dequeue packet */
              skb = dequeue_skb(q);
              if (unlikely(!skb))
                      return 0;
              WARN_ON_ONCE(skb_dst_is_noref(skb));
              root_lock = qdisc_lock(q);
              dev = qdisc_dev(q);
              txq = netdev_get_tx_queue(dev, skb_get_queue_mapping(skb));

              return sch_direct_xmit(skb, q, dev, txq, root_lock);
      }    
    #+END_SRC

    The =qdisc_restart= function begins with a useful comment describing
    some of the locking constraints for calling this function. The
    first operation this function performs is to attempt to dequeue an
    skb from the qdisc. 

    The function =dequeue_skb= will attempt to obtain the next packet to
    transmit. If the queue is empty =qdisc_restart= will return false
    (causing the loop in =__qdisc_run= above to bail). 
    
    Assuming there is data to transmit, the code continues by
    obtaining a reference to the qdisc queue lock, the qdisc’s
    associated device, and the transmit queue. 

    All of these are passed through to =sch_direct_xmit=. Let’s take a
    look at =dequeue_skb= and then we’ll come back
    =sch_direct_xmit=. 
    
**** =dequeue_skb=
     Let’s take a look at =dequeue_skb= from
     [[https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L59-L78][./net/sched/sch_generic.c]]. This function handles two major cases: 

     1. Dequeuing data that was requeued because it could not be sent
        before, or
     2. Dequeuing new data from the qdisc to be processed.

     Let’s take a look at the first case:

     #+BEGIN_SRC c
       static inline struct sk_buff *dequeue_skb(struct Qdisc *q)
       {
               struct sk_buff *skb = q->gso_skb;
               const struct netdev_queue *txq = q->dev_queue;

               if (unlikely(skb)) {
                       /* check the reason of requeuing without tx lock first */
                       txq = netdev_get_tx_queue(txq->dev, skb_get_queue_mapping(skb));
                       if (!netif_xmit_frozen_or_stopped(txq)) {
                               q->gso_skb = NULL;
                               q->q.qlen--;
                       } else
                               skb = NULL;     
     #+END_SRC
     
     Note that the code begins by taking a reference to =gso_skb= field
     of the qdisc. This field holds a reference to data that was
     requeued. If no data was requeued, this field will be =NULL=. If
     that field is not =NULL=, the code continues by getting the
     transmit queue for the data and checking if the queue is
     stopped. If the queue is not stopped, the =gso_skb= field is
     cleared and the queue length counter is decreased. If the queue
     is stopped, the data remains attached to =gso_skb=, but =NULL= will
     be returned from this function. 

     Let’s check the next case, where there is no data that was
     requeued:

     #+BEGIN_SRC c
       } else {
                       if (!(q->flags & TCQ_F_ONETXQUEUE) || !netif_xmit_frozen_or_stopped(txq))
                               skb = q->dequeue(q);
               }

               return skb;
       }     
     #+END_SRC

     In the case where no data was requeued, another tricky compound
     if statement is evaluated. If: 
     
     1. The qdisc does not have a single transmit queue, or
     2. The transmit queue is not stopped

     Then, the qdisc’s =dequeue= function will be called to obtain new
     data. The internal implementation of =dequeue= will vary depending
     on the qdisc’s implementation and features.    

     The function finishes by returning the data that is up for
     processing. 
     
**** =sch_direct_xmit=
     Now we come to =sch_direct_xmit= (in [[https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L109-L154][./net/sched/sch_generic.c]])
     which is an important participant in moving data down toward the
     network device. Let’s walk through it, piece by piece: 

     #+BEGIN_SRC c
       /*
        ,* Transmit one skb, and handle the return status as required. Holding the
        ,* __QDISC_STATE_RUNNING bit guarantees that only one CPU can execute this
        ,* function.
        ,*
        ,* Returns to the caller:
        ,*                                0  - queue is empty or throttled.
        ,*                                >0 - queue is not empty.
        ,*/
       int sch_direct_xmit(struct sk_buff *skb, struct Qdisc *q,
                           struct net_device *dev, struct netdev_queue *txq,
                           spinlock_t *root_lock)
       {
               int ret = NETDEV_TX_BUSY;

               /* And release qdisc */
               spin_unlock(root_lock);

               HARD_TX_LOCK(dev, txq, smp_processor_id());
               if (!netif_xmit_frozen_or_stopped(txq))
                       ret = dev_hard_start_xmit(skb, dev, txq);

               HARD_TX_UNLOCK(dev, txq);     
     #+END_SRC

     The code begins by unlocking the qdisc lock and then locking the
     transmit lock. Note that =HARD_TX_LOCK= is a macro: 

     #+BEGIN_SRC c
       #define HARD_TX_LOCK(dev, txq, cpu) {                   \
               if ((dev->features & NETIF_F_LLTX) == 0) {      \
                       __netif_tx_lock(txq, cpu);              \
               }                                               \
       }     
     #+END_SRC

     This macro is checking if the device has the NETIF_F_LLTX flag
     set in its feature flags. This flag is deprecated and should not
     be used by new device drivers. Most drivers in this kernel
     version do not use this flag, so this check will evaluate to to
     true and the lock for the transmit queue for this data will be
     obtained. 

     Next, the transmit queue is checked to ensure that it is not
     stopped and then =dev_hard_start_xmit= is called. As we’ll see
     later, =dev_hard_start_xmit= handles transitioning the network data
     from the Linux kernel’s network device subsystem into the device
     driver itself for transmission. The return code from this
     function is stored and will be checked next to determine if the
     transmit succeeded. 

     Once this has run (or been skipped because the queue is stopped),
     the queue’s transmit lock is released. Let’s continue: 

     #+BEGIN_SRC c
       spin_lock(root_lock);

               if (dev_xmit_complete(ret)) {
                       /* Driver sent out skb successfully or skb was consumed */
                       ret = qdisc_qlen(q);
               } else if (ret == NETDEV_TX_LOCKED) {
                       /* Driver try lock failed */
                       ret = handle_dev_cpu_collision(skb, txq, q);     
     #+END_SRC

     Next, the lock for this qdisc is taken again and then the return
     value of =dev_hard_start_xmit= is examined. The first case is
     checked by calling =dev_xmit_complete= which simply checks the
     return value to determine if the data was sent successfully. If
     so the qdisc queue length is set as the return value. 

     If =dev_xmit_complete= returns false, the return value will be
     checked to see if =dev_hard_start_xmit= returned =NETDEV_TX_LOCKED=
     up from the device driver. Devices with the deprecated
     =NETIF_F_LLTX= feature flag can return =NETDEV_TX_LOCKED= when the
     driver attempts to do its own locking of the transmit queue and
     fails. In this case, =handle_dev_cpu_collision= is called to deal
     with the lock contention. We’ll take a closer look at
     =handle_dev_cpu_collision= shortly, but for now, let’s continue
     down =sch_direct_xmit= and check out the catch-all case: 

     #+BEGIN_SRC c
       } else {
                       /* Driver returned NETDEV_TX_BUSY - requeue skb */
                       if (unlikely(ret != NETDEV_TX_BUSY))
                               net_warn_ratelimited("BUG %s code %d qlen %d\n",
                                                    dev->name, ret, q->q.qlen);

                       ret = dev_requeue_skb(skb, q);
               }     
     #+END_SRC

     So if the driver did not transmit the data and it was not due to
     the transmit lock being held, it is probably due to
     =NETDEV_TX_BUSY= (if not a warning is printed). =NETDEV_TX_BUSY= can
     be returned by a driver to indicate that either the device or the
     driver were “busy” and the data can not be transmit right
     now. In this case, =dev_requeue_skb= is used to queue the data to
     be retried. 

     The function wraps up by (possibly) adjusting the return value:

     #+BEGIN_SRC c
       if (ret && netif_xmit_frozen_or_stopped(txq))
                       ret = 0;

               return ret;     
     #+END_SRC

     Let’s a take a dive into =handle_dev_cpu_collision= and
     =dev_requeue_skb=. 
     
**** =handle_dev_cpu_collision=
     The code for =handle_dev_cpu_collision=, from
     [[https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L80-L107][./net/sched/sch_generic.c]] handles two cases:

     1. The transmit lock is held by the current CPU.
     2. The transmit lock is held by some other CPU.

     In the first case, this is handled as a configuration problem and
     thus a warning is printed. In the second case a statistic counter
     =cpu_collision= is incremented and the data is sent through
     =dev_requeue_skb= to be requeued for transmission later. Recall
     earlier we saw code in =dequeue_skb= that dealt specifically with
     requeued skbs.    

     The code for =handle_dev_cpu_collision= is short and worth a quick
     read: 

     #+BEGIN_SRC c
       static inline int handle_dev_cpu_collision(struct sk_buff *skb,
                                                  struct netdev_queue *dev_queue,
                                                  struct Qdisc *q)
       {
               int ret;

               if (unlikely(dev_queue->xmit_lock_owner == smp_processor_id())) {
                       /*
                        ,* Same CPU holding the lock. It may be a transient
                        ,* configuration error, when hard_start_xmit() recurses. We
                        ,* detect it by checking xmit owner and drop the packet when
                        ,* deadloop is detected. Return OK to try the next skb.
                        ,*/
                       kfree_skb(skb);
                       net_warn_ratelimited("Dead loop on netdevice %s, fix it urgently!\n",
                                            dev_queue->dev->name);
                       ret = qdisc_qlen(q);
               } else {
                       /*
                        ,* Another cpu is holding lock, requeue & delay xmits for
                        ,* some time.
                        ,*/
                       __this_cpu_inc(softnet_data.cpu_collision);
                       ret = dev_requeue_skb(skb, q);
               }

               return ret;
       }     
     #+END_SRC

     Let’s take a look at what =dev_requeue_skb= does, as we’ll see
     this function called from =sch_direct_xmit=. 
     
**** =dev_requeue_skb=
     Thankfully, the source for =dev_requeue_skb= is short and straight
     to the point, from [[https://github.com/torvalds/linux/blob/v3.13/net/sched/sch_generic.c#L39-L57][./net/sched/sch_generic.c]]: 

     #+BEGIN_SRC c
       /* Modifications to data participating in scheduling must be protected with
        ,* qdisc_lock(qdisc) spinlock.
        ,*
        ,* The idea is the following:
        ,* - enqueue, dequeue are serialized via qdisc root lock
        ,* - ingress filtering is also serialized via qdisc root lock
        ,* - updates to tree and tree walking are only done under the rtnl mutex.
        ,*/

       static inline int dev_requeue_skb(struct sk_buff *skb, struct Qdisc *q)
       {
               skb_dst_force(skb);
               q->gso_skb = skb;
               q->qstats.requeues++;
               q->q.qlen++;        /* it's still part of the queue */
               __netif_schedule(q);

               return 0;
       }     
     #+END_SRC

     This function does a few things:

     1. It forces a reference count on the skb.
     2. It attaches the skb to the qdisc’s =gso_skb= field. Recall
        earlier we saw that this field is checked in =dequeue_skb=
        before data is pulled off the qdisc’s queue.
     3. A statistics counter is bumped.
     4. The size of the queue is increased.
     5. =__netif_schedule= is called.

     Simple and straightforward. Let’s refresh how we got here and
     then examine =__netif_schedule=.    
     
*** Reminder, while loop in =__qdisc_run=
    Recall that we got here by examining the function =__qdisc_run=
    which contained the following code: 

    #+BEGIN_SRC c
      void __qdisc_run(struct Qdisc *q)
      {
              int quota = weight_p;

              while (qdisc_restart(q)) {
                      /*
                       ,* Ordered by possible occurrence: Postpone processing if
                       ,* 1. we've exceeded packet quota
                       ,* 2. another process needs the CPU;
                       ,*/
                      if (--quota <= 0 || need_resched()) {
                              __netif_schedule(q);
                              break;
                      }
              }

              qdisc_run_end(q);
      }    
    #+END_SRC

    This code works by repeatedly calling =qdisc_restart= in a loop
    which, internally, dequeues skbs, attempts to transmit them by
    calling =sch_direct_xmit=, which calls =dev_hard_start_xmit= to get
    down to the driver to do the actual transmit. Anything that could
    not be transmit is requeued to be transmit in the =NET_TX=
    softirq. 

    The next step in the transmit process is examining
    =dev_hard_start_xmit= to see how the drivers are invoked for sending
    data. Before doing that, we should examine =__netif_schedule= to
    fully understand how both =__qdisc_run= and =dev_requeue_skb= work. 

**** =__netif_schedule=
     Let’s jump into =__netif_schedule= from [[https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L2127-L2146][./net/core/dev.c]]: 

     #+BEGIN_SRC c
       void __netif_schedule(struct Qdisc *q)
       {
               if (!test_and_set_bit(__QDISC_STATE_SCHED, &q->state))
                       __netif_reschedule(q);
       }
       EXPORT_SYMBOL(__netif_schedule);     
     #+END_SRC

     This code checks and sets the =__QDISC_STATE_SCHED= bit in the
     qdisc’s state. If the bit was flipped (meaning that it was not
     previously in the =__QDISC_STATE_SCHED= state), the code will call
     =__netif_reschedule=, which is not much longer but has very
     interesting side effects. Let’s take a look: 

     #+BEGIN_SRC c
       static inline void __netif_reschedule(struct Qdisc *q)
       {
               struct softnet_data *sd;
               unsigned long flags;

               local_irq_save(flags);
               sd = &__get_cpu_var(softnet_data);
               q->next_sched = NULL;
               ,*sd->output_queue_tailp = q;
               sd->output_queue_tailp = &q->next_sched;
               raise_softirq_irqoff(NET_TX_SOFTIRQ);
               local_irq_restore(flags);
       }     
     #+END_SRC

     This function does several things:

     1. Save the current local IRQ state and disable IRQs with a call
        to =local_irq_save=.
     2. Get the current CPUs =softnet_data= structure.
     3. Add the qdisc to the =softnet_data’s= output queue.
     4. Raise the =NET_TX_SOFTIRQ= softirq.
     5. Restore the IRQ state and re-enable interrupts.

     You can read more about the initialization of the softnet_data
     data structures by reading our previous post about the receive
     side of the networking stack. 
     
     The important piece of code in the above function is:
     =raise_softirq_irqoff= which triggers the =NET_TX_SOFTIRQ=
     softirq. softirqs and their registration are also covered in our
     previous post. Briefly, you can think of softirqs are kernel
     threads that execute with a very high priority and process data
     on behalf of the kernel. They are used for processing incoming
     network data and also for processing outgoing data. 
     
     As you’ll see from the previous post, the =NET_TX_SOFTIRQ= softirq
     has the function =net_tx_action= registered to it. This means that
     there is a kernel thread executing =net_tx_action=. That thread is
     occasionally paused and =raise_softirq_irqoff= resumes it. Let’s
     take a look at what =net_tx_action= does so we can understand how
     the kernel processes transmit requests. 
     
**** =net_tx_action=
     The =net_tx_action= function from [[https://github.com/torvalds/linux/blob/v3.13/net/core/dev.c#L3297-L3353][./net/core/dev.c]] handles two main
     things when it runs: 
     
     1. The completion queue of the =softnet_data= structure for the
        executing CPU.
     2. The output queue of the =softnet_data= structure for the
        executing CPU. 

     In fact, the code for the function is two large if blocks. Let’s
     take them one at a time, remembering all the while that this code
     is executing in the softirq context as an independent kernel
     thread. The purpose of =net_tx_action= is to execute code that
     cannot be executed in hot paths throughout the transmit side of
     the network stack; work is deferred and later processed by the
     thread executing =net_tx_action=.    
     
***** =net_tx_action= completion queue
      The =softnet_data’s= completion queue is simply a queue of skbs
      that are waiting to be freed. The function =dev_kfree_skb_irq= can
      be used to add skbs to a queue to be freed later. This is
      commonly used by device drivers to defer freeing consumed
      skbs. The reason why a driver would want to defer freeing the
      skb instead of simply freeing the skb is that freeing memory can
      take time and there are instances (like hardirq handlers) where
      code needs to execute as quickly as possible and return. 

      Take a look at the =net_tx_action= code which deals with freeing
      skbs on the completion queue: 

      #+BEGIN_SRC c
        if (sd->completion_queue) {
                        struct sk_buff *clist;

                        local_irq_disable();
                        clist = sd->completion_queue;
                        sd->completion_queue = NULL;
                        local_irq_enable();

                        while (clist) {
                                struct sk_buff *skb = clist;
                                clist = clist->next;

                                WARN_ON(atomic_read(&skb->users));
                                trace_kfree_skb(skb, net_tx_action);
                                __kfree_skb(skb);
                        }
                }      
      #+END_SRC

      If the completion queue has entries, the while loop will walk
      through the linked list of skbs and call =__kfree_skb= on each of
      them to free their memory. Remember, this code is running in a
      separate “thread” called a softirq – it is not running on
      behalf of any user program in particular. 

***** =net_tx_action= output queue
      The output queue serves a different purpose entirely. As we saw
      earlier, data is added to the output queue by calls to
      =__netif_reschedule=, which is typically called from
      =__netif_schedule=. The =__netif_schedule= function is called in two
      instances we’ve seen so far: 

      - =dev_requeue_skb=: As we saw, this function can be called if the
        driver reports back the error code =NETDEV_TX_BUSY= or if there
        is a CPU collision.
      - =__qdisc_run=: We saw this function earlier, as well. It also
        calls =__netif_schedule= once the quota has been exceeded or if
        the process needs to be rescheduled. 

      In either of those cases, the =__netif_schedule= function will be
      called which will add the qdisc to the =softnet_data’s= output
      queue for processing. I’ve split out the output queue
      processing code into three blocks. Let’s take a look at the
      first:   
      
      #+BEGIN_SRC c
        if (sd->output_queue) {
                        struct Qdisc *head;

                        local_irq_disable();
                        head = sd->output_queue;
                        sd->output_queue = NULL;
                        sd->output_queue_tailp = &sd->output_queue;
                        local_irq_enable();      
      #+END_SRC

      This block simply ensures that there are qdiscs on the output
      queue, and if so, it sets =head= to the first entry and moves the
      tail pointer of the queue. 
 
